{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Vocoder - Time Scale & Pitch Shift with Short Time Fourier Transforms\n",
    "\n",
    "This is a demonstration of stretching, shrinking, and resampling audio with a phase vocoder.\n",
    "The algorithm uses the formulas and descriptions from:\n",
    "\n",
    "\n",
    " J. Laroche and M. Dolson (1999). \"Improved Phase Vocoder Time-Scale Modification of Audio\". IEEE Transactions on Speech and Audio Processing. 7 (3): 323â€“332. doi:10.1109/89.759041."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as nprandom\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal\n",
    "import scipy.fft\n",
    "import scipy.signal.windows\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import pdb\n",
    "from ipywidgets import widgets\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [24, 12]\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# load up a wav file containing our audio\n",
    "y2k_sample_rate, year_2000_data = scipy.io.wavfile.read(\"./audio/year2000.wav\")\n",
    "IPython.display.Audio(data = year_2000_data, rate = y2k_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Time Fourier Transform\n",
    "\n",
    "## Analysis Step\n",
    "$$X(t_a^u, \\Omega_k) = \\sum_{n=-\\infty}^{\\infty}h(n)x(t_a^u + n)e^{-j\\Omega_k n}$$\n",
    "Where:\n",
    "\n",
    "$x$ is the input signal.\n",
    "\n",
    "$h(n)$ is the analysis Hann window.\n",
    "\n",
    "$\\Omega_k = \\frac{2 \\pi k}{N}$ is the frequency of the kth channel.\n",
    "\n",
    "$N$ is the DFT size.\n",
    "\n",
    "\n",
    "\n",
    "## Synthesis Step\n",
    "$$y(n) = \\sum_{u=-\\infty}^{\\infty} y_u(n-t_s^u)$$\n",
    "\n",
    "$$y_u(n) = \\frac{1}{N} \\sum_{k=0}^{N-1} Y(t_s^u, \\Omega_k) e^{j\\Omega_k n}$$\n",
    "\n",
    "This stft is modified from the analysis stft by:\n",
    "\n",
    "\n",
    "$$|Y(t_s^u, \\Omega_k)| = |X(t_a^u, \\Omega_k)|$$\n",
    "\n",
    "$$\\angle Y(t_s^u, \\Omega_k) = \\angle Y(t_s^{u-1}, \\Omega_k) + R_s \\hat{\\omega}_k(t_a^u)$$\n",
    "\n",
    "$$\\hat{\\omega}_k(t_a^u) = \\Omega_k + \\frac{1}{R_a}\\Delta_p \\Phi_k^u$$\n",
    "\n",
    "$$ \\Delta \\Phi_k^u = \\angle X(t_a^u, \\Omega_k) - \\angle X(t_a^{u-1}, \\Omega_k) - R_a \\Omega_k $$\n",
    "\n",
    "$\\Delta_p \\Phi_k^u$ is $\\Delta \\Phi_k^u$ unrawpped between $\\pm \\pi$.\n",
    "\n",
    "$t_a^u = uR_a$ where $R_a$ is the hop factor during analysis. \n",
    "\n",
    "$t_s^u = uR_s$ where $R_s$ is the hop factor during the synthesis stage.\n",
    "\n",
    "$t_s^u = \\alpha t_a^u$ for some scaling factor $\\alpha$. So, $R_s = \\alpha R_a$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "N = 2**12\n",
    "R_a = N//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def short_time_fourier_transform(data, window_size, analysis_hop_size):\n",
    "        \n",
    "    total_windows = (len(data) - window_size) // analysis_hop_size\n",
    "    # create output buffer, a 2D array where each row is the FFT of the next slice of data\n",
    "    output = np.zeros((total_windows, window_size), dtype=complex)\n",
    "    # create the window to smooth  the FFT segments\n",
    "    window = scipy.signal.windows.hann(window_size, sym=False)\n",
    "\n",
    "    # break data into overlapping windowed chunks, perform fft on each chunk, store results as a rows\n",
    "    for hop in range(0, total_windows):\n",
    "        hop_location = hop * analysis_hop_size\n",
    "        windowed_data = window * data[hop_location: hop_location + window_size]\n",
    "        fft = scipy.fft.fft(windowed_data)\n",
    "        output[hop] = fft\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y2k_stft = short_time_fourier_transform(year_2000_data, N, R_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the STFT over Time\n",
    "plt.pcolormesh(np.abs(y2k_stft.T), cmap=plt.get_cmap('magma'))\n",
    "plt.ylim(0, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Vocoder - Inverse STFT with Different Hop Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def synthesis_phase_spectrum(stft, analysis_hop_size, synthesis_hop_size, omegas):\n",
    "    TAU = 2 * np.pi\n",
    "    phases = np.angle(stft)\n",
    "    delta_phases = phases - np.roll(phases, 1, axis=0) - (analysis_hop_size * omegas)\n",
    "    unwrapped_delta_phases = delta_phases - TAU * np.round(delta_phases / TAU)\n",
    "    instantaneous_frequencies = omegas + (unwrapped_delta_phases / analysis_hop_size)\n",
    "    for i in range(1, len(stft)):\n",
    "        phases[i] = phases[i-1] + (synthesis_hop_size * instantaneous_frequencies[i])\n",
    "        \n",
    "    return phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def phase_vocoder_istft(stft, analysis_hop_size, factor):\n",
    "    \n",
    "    synthesis_hop_size = int(analysis_hop_size * factor)\n",
    "    \n",
    "    num_frames = len(stft)\n",
    "    N = len(stft[0])  # DFT size\n",
    "    \n",
    "    window = scipy.signal.windows.hann(N, sym=False)\n",
    "    omegas = (2 * np.pi * np.arange(N)) / N\n",
    "    \n",
    "    magnitude_spectrum = np.abs(stft)\n",
    "    synth_phase_spectrum = synthesis_phase_spectrum(stft, analysis_hop_size, synthesis_hop_size, omegas)\n",
    "    \n",
    "    output = np.zeros(synthesis_hop_size * (num_frames - 1) + N)\n",
    "    \n",
    "    # change the current frame to use the same magnitudes from the analysis step but the adjusted phase values\n",
    "    corrected_spectrums = magnitude_spectrum * np.exp(synth_phase_spectrum * 1j)\n",
    "    \n",
    "    # Now, do inverse FFTs at intervals of the synthesis hop size, summing the results together.\n",
    "    for hop in range(0, num_frames):\n",
    "        ifft = np.real(scipy.fft.ifft(corrected_spectrums[hop]))\n",
    "        hop_location = hop * synthesis_hop_size\n",
    "        output[hop_location: hop_location + N] += window * ifft\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "voice_stretch_factor = 1.122462\n",
    "stretched = phase_vocoder_istft(y2k_stft, R_a, voice_stretch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = stretched, rate = y2k_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, autotune the voice up by playing the stretched version at a faster rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data = stretched, rate = y2k_sample_rate * voice_stretch_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch Changing Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musical pitches are related to each other by adjacent semitones having a ratio of $2^{1/12}$. So, an $n$ semitone shift is equal to $(2^{1/12})^n = 2^{n/12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to convert a number of semitones to pitch shift into the \n",
    "# length factor that the phase vocoder algorithm expects\n",
    "def semitones_to_ratio(n):\n",
    "    return np.power(2, n/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that makes time stretched and pitch scaled version of\n",
    "# the input file name and then displays IPython Audio elements for them\n",
    "def show_autotune_example(path, dft_size, analysis_hop, factor):\n",
    "    fs, data = scipy.io.wavfile.read(path)\n",
    "    stft = short_time_fourier_transform(data, N, analysis_hop)\n",
    "    stretched = phase_vocoder_istft(stft, analysis_hop, factor)\n",
    "    out = [\n",
    "    (IPython.display.Audio(data = data, rate = fs)),\n",
    "    (IPython.display.Audio(data = stretched, rate = fs)),\n",
    "    (IPython.display.Audio(data = stretched, rate = fs * factor))]\n",
    "    for x in out:\n",
    "        IPython.display.display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bach - Violin Concerto in A minor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we speed up this performance of Bach's Violin Concerto in A Minor, but keep it _in_ A minor. :)\n",
    "Then, if we speed the audio but scale the sample rate by the same amount we scaled the duration, we get a pitch shift (Auto-Tune)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_autotune_example(\"./audio/BachConcertoAMinor_Intro.wav\", N, R_a, semitones_to_ratio(-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervals - I'm Awake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_autotune_example(\"./audio/IntervalsImAwake.wav\", N, R_a, semitones_to_ratio(-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dead South - In Hell I'll be in Good Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_autotune_example(\"./audio/HellGoodCompany.wav\", N, R_a, semitones_to_ratio(-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beethoven - Moonlight Sonata, 3rd movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_autotune_example(\"./audio/moonlight.wav\", N, R_a, semitones_to_ratio(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nikolai Rimsky-Korsakov - Flight of the Bumblebee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_autotune_example(\"./audio/bumblebee.wav\", N, R_a, 165/325)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Christopher Tin - Temen Oblak(\"Dark Clouds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_autotune_example(\"./audio/DarkClouds.wav\", N, R_a, semitones_to_ratio(-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, data = scipy.io.wavfile.read(\"./audio/bumblebee.wav\")\n",
    "stft = short_time_fourier_transform(data, N, R_a)\n",
    "stretched = phase_vocoder_istft(stft, R_a, 165/325)\n",
    "stretched/=np.max(stretched)\n",
    "#IPython.display.Audio(data=stretched, rate=fs)\n",
    "#scipy.io.wavfile.write(\"fastBee.wav\", fs, stretched)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
